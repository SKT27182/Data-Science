{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C3/W1/ungraded_labs/C3_W1_Lab_1_tokenize_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rL-LzAqpoGLC"
   },
   "source": [
    "# Ungraded Lab: TextVectorization Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-nt3uR9TPrUt"
   },
   "source": [
    "## Generating the vocabulary\n",
    "\n",
    "The code below takes a list of sentences, then takes each word in those sentences and assigns it to an integer. This is done using the [adapt()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) method and you can get the vocabulary by looking at the `get_vocabulary` property. More frequent words have a lower index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zaCMcjMQifQc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'my', 'love', 'i', 'dog', 'cat']\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# Define input sentences\n",
    "sentences = [\n",
    "    'i love my dog',\n",
    "    'I, love my cat'\n",
    "    ]\n",
    "\n",
    "# Initialize the Tokenizer class\n",
    "tokenizer = TextVectorization(max_tokens = 100, output_mode = 'int', output_sequence_length = 5)\n",
    "\n",
    "# Generate indices for each word in the corpus\n",
    "tokenizer.adapt(sentences)\n",
    "\n",
    "# Get the vocabulary\n",
    "word_index = tokenizer.get_vocabulary()\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3 2 5 0]\n",
      " [4 3 2 6 0]]\n"
     ]
    }
   ],
   "source": [
    "# get the specific encoding of each sentence\n",
    "sequences = tokenizer(sentences)\n",
    "print(sequences.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- here we can see that `output_sequence_length` is set to 5, so the output vectors will have a length of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": []\n",
      "[UNK]: [1 0 0 0 0]\n",
      "my: [2 0 0 0 0]\n",
      "love: [3 0 0 0 0]\n",
      "i: [4 0 0 0 0]\n",
      "dog: [5 0 0 0 0]\n",
      "cat: [6 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary\n",
    "vocabulary = tokenizer.get_vocabulary()\n",
    "\n",
    "# Iterate over the vocabulary and print the token assigned to each word\n",
    "for word in vocabulary:\n",
    "    print(f\"{word}: {tokenizer(word)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uTPWesNaRdX2"
   },
   "source": [
    "The `max_tokens` parameter used in the initializer specifies the maximum number of words minus one (minus one if output_mode is int) (based on frequency) to keep when generating sequences. You will see this in a later exercise. For now, the important thing to note is it does affect how the `vocabulary` is generated. You can try passing `3` instead of `100` as shown on the next cell and you will see that the dictionary only contains three words.\n",
    "\n",
    "Also notice that by default, all punctuation is ignored and words are converted to lower case. You can override these behaviors by modifying the `filters` and `lower` arguments of the `TextVectorization` class as described [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer#arguments). You can try modifying these in the next cell below and compare the output to the one generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VX1A1pDNoVKm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'my']\n"
     ]
    }
   ],
   "source": [
    "# Define input sentences\n",
    "sentences = [\n",
    "    'i love my dog',\n",
    "    'I, love my cat',\n",
    "    'You love my dog!'\n",
    "]\n",
    "\n",
    "# Initialize the Tokenizer class\n",
    "tokenizer = TextVectorization(max_tokens = 3, output_mode='int')\n",
    "\n",
    "# Generate indices for each word in the corpus\n",
    "tokenizer.adapt(sentences)\n",
    "\n",
    "# Get the indices and print it\n",
    "word_index = tokenizer.get_vocabulary()\n",
    "print(word_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- here we have set `max_tokens` to 3, so our vocabulary will only contain 3 words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "c9LFfwBffDaj"
   },
   "source": [
    "That concludes this short exercise on tokenizing input texts!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C3_W1_Lab_1_tokenize_basic.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C3/C3/W1/ungraded_labs/C3_W1_Lab_1_tokenize_basic.ipynb",
     "timestamp": 1642431620601
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
