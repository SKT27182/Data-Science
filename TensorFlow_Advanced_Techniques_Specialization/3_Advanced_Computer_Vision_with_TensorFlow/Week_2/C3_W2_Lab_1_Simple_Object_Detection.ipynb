{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmANPR2jhCR6"
      },
      "source": [
        "# Simple Object Detection in Tensorflow\n",
        "\n",
        "This lab will walk you through how to use object detection models available in [Tensorflow Hub](https://www.tensorflow.org/hub). In the following sections, you will:\n",
        "\n",
        "* explore the Tensorflow Hub for object detection models\n",
        "* load the models in your workspace\n",
        "* preprocess an image for inference \n",
        "* run inference on the models and inspect the output\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkMLuGDhCR6"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEoRKdmByrb0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb8MBgTOhCR6"
      },
      "source": [
        "### Download the model from Tensorflow Hub\n",
        "\n",
        "Tensorflow Hub is a repository of trained machine learning models which you can reuse in your own projects. \n",
        "- You can see the domains covered [here](https://tfhub.dev/) and its subcategories. \n",
        "- For this lab, you will want to look at the [image object detection subcategory](https://tfhub.dev/s?module-type=image-object-detection). \n",
        "- You can select a model to see more information about it and copy the URL so you can download it to your workspace. \n",
        "- We selected a [inception resnet version 2](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1)\n",
        "- You can also modify this following cell to choose the other model that we selected, [ssd mobilenet version 2](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9pCzz4uy20U"
      },
      "source": [
        "# you can switch the commented lines here to pick the other model\n",
        "\n",
        "# inception resnet version 2\n",
        "# module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
        "\n",
        "# You can choose ssd mobilenet version 2 instead and compare the results\n",
        "module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3trj5FbhCR6"
      },
      "source": [
        "#### Load the model\n",
        "\n",
        "Next, you'll load the model specified by the `module_handle`.\n",
        "- This will take a few minutes to load the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WHkGDHfhCR6"
      },
      "source": [
        "model = hub.load(module_handle)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ey0FpHGhCR6"
      },
      "source": [
        "#### Choose the default signature\n",
        "\n",
        "Some models in the Tensorflow hub can be used for different tasks. So each model's documentation should show what *signature* to use when running the model. \n",
        "- If you want to see if a model has more than one signature then you can do something like `print(hub.load(module_handle).signatures.keys())`. In your case, the models you will be using only have the `default` signature so you don't have to worry about other types."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hub.load(module_handle).signatures.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjmAXYODIRbp",
        "outputId": "8f7b94d9-c1f2-4ab4-d9d7-5ab3c681895c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeysView(_SignatureMap({'default': <ConcreteFunction pruned(images) at 0x7EFBD1144310>}))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1BU7AGthCR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a080d3c4-af94-4784-a225-6265d8c4b46e"
      },
      "source": [
        "# take a look at the available signatures for this particular model\n",
        "model.signatures.keys()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KeysView(_SignatureMap({'default': <ConcreteFunction pruned(images) at 0x7EFC64C0D370>}))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfc9ax9hhCR6"
      },
      "source": [
        "Please choose the 'default' signature for your object detector.\n",
        "- For object detection models, its 'default' signature will accept a batch of image tensors and output a dictionary describing the objects detected, which is what you'll want here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzwR5zE_hCR7"
      },
      "source": [
        "detector = model.signatures['default']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvb-3r3thCR7"
      },
      "source": [
        "### download_and_resize_image\n",
        "\n",
        "This function downloads an image specified by a given \"url\", pre-processes it, and then saves it to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucsxak_qhCR7"
      },
      "source": [
        "def download_and_resize_image(url, new_width=256, new_height=256):\n",
        "    '''\n",
        "    Fetches an image online, resizes it and saves it locally.\n",
        "    \n",
        "    Args:\n",
        "        url (string) -- link to the image\n",
        "        new_width (int) -- size in pixels used for resizing the width of the image\n",
        "        new_height (int) -- size in pixels used for resizing the length of the image\n",
        "        \n",
        "    Returns:\n",
        "        (string) -- path to the saved image\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # create a temporary file ending with \".jpg\"\n",
        "    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "    \n",
        "    # opens the given URL\n",
        "    response = urlopen(url)\n",
        "    \n",
        "    # reads the image fetched from the URL\n",
        "    image_data = response.read()\n",
        "    \n",
        "    # puts the image data in memory buffer\n",
        "    image_data = BytesIO(image_data)\n",
        "    \n",
        "    # opens the image\n",
        "    pil_image = Image.open(image_data)\n",
        "    \n",
        "    # resizes the image. will crop if aspect ratio is different.\n",
        "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "    \n",
        "    # converts to the RGB colorspace\n",
        "    pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "    \n",
        "    # saves the image to the temporary file created earlier\n",
        "    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "    \n",
        "    print(\"Image downloaded to %s.\" % filename)\n",
        "    \n",
        "    return filename"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qodEJHhCR7"
      },
      "source": [
        "### Download and preprocess an image\n",
        "\n",
        "Now, using `download_and_resize_image` you can get a sample image online and save it locally. \n",
        "- We've provided a URL for you, but feel free to choose another image to run through the object detector.\n",
        "- You can use the original width and height of the image but feel free to modify it and see what results you get."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHTDalVrhCR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea8f6b4-2a98-4fb9-b07f-7f47662032e7"
      },
      "source": [
        "# You can choose a different URL that points to an image of your choice\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n",
        "\n",
        "# download the image and use the original height and width\n",
        "downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image downloaded to /tmp/tmp_czxnrpb.jpg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVNXUKMIhCR7"
      },
      "source": [
        "### run_detector\n",
        "\n",
        "This function will take in the object detection model `detector` and the path to a sample image, then use this model to detect objects and display its predicted class categories and detection boxes.\n",
        "- run_detector uses `load_image` to convert the image into a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkkiQzKlhCR7"
      },
      "source": [
        "def load_img(path):\n",
        "    '''\n",
        "    Loads a JPEG image and converts it to a tensor.\n",
        "    \n",
        "    Args:\n",
        "        path (string) -- path to a locally saved JPEG image\n",
        "    \n",
        "    Returns:\n",
        "        (tensor) -- an image tensor\n",
        "    '''\n",
        "    \n",
        "    # read the file\n",
        "    img = tf.io.read_file(path)\n",
        "    \n",
        "    # convert to a tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    \n",
        "    return img\n",
        "\n",
        "\n",
        "def run_detector(detector, path):\n",
        "    '''\n",
        "    Runs inference on a local file using an object detection model.\n",
        "    \n",
        "    Args:\n",
        "        detector (model) -- an object detection model loaded from TF Hub\n",
        "        path (string) -- path to an image saved locally\n",
        "    '''\n",
        "    \n",
        "    # load an image tensor from a local file path\n",
        "    img = load_img(path)\n",
        "\n",
        "    # add a batch dimension in front of the tensor\n",
        "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "    \n",
        "    # run inference using the model\n",
        "    result = detector(converted_img)\n",
        "\n",
        "    # save the results in a dictionary\n",
        "    result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "    # print results\n",
        "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "\n",
        "    print(result[\"detection_scores\"])\n",
        "    print(result[\"detection_class_entities\"])\n",
        "    print(result[\"detection_boxes\"])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSEeJSkxhCR7"
      },
      "source": [
        "### Run inference on the image\n",
        "\n",
        "You can run your detector by calling the `run_detector` function. This will print the number of objects found followed by three lists: \n",
        "\n",
        "* The detection scores of each object found (i.e. how confident the model is), \n",
        "* The classes of each object found, \n",
        "* The bounding boxes of each object\n",
        "\n",
        "You will see how to overlay this information on the original image in the next sections and in this week's assignment!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csanHvDIz4_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08cbfff1-0c1c-436e-e6dc-ce1bfbf6595e"
      },
      "source": [
        "# runs the object detection model and prints information about the objects found\n",
        "run_detector(detector, downloaded_image_path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 objects.\n",
            "[0.43670568 0.34758788 0.24386634 0.23315553 0.22782986 0.2141637\n",
            " 0.20577559 0.20488328 0.20278914 0.1984365  0.18925612 0.18167147\n",
            " 0.18141809 0.18016164 0.17810726 0.17738226 0.17522177 0.17424867\n",
            " 0.17037816 0.1695776  0.16904221 0.16812502 0.1645604  0.1627204\n",
            " 0.16027097 0.16010652 0.16001624 0.15941426 0.15788303 0.15728986\n",
            " 0.15717909 0.15715134 0.15316628 0.1521397  0.15061927 0.1487934\n",
            " 0.14763562 0.14687383 0.14668058 0.14592563 0.14561154 0.14550842\n",
            " 0.14460723 0.1444365  0.14373197 0.14367627 0.14334667 0.14312641\n",
            " 0.14064184 0.13832898 0.13809706 0.1379262  0.13692595 0.13685746\n",
            " 0.13657333 0.13628234 0.13564982 0.13426593 0.12963866 0.1280813\n",
            " 0.12806708 0.1273184  0.12692001 0.12569717 0.12567624 0.12357565\n",
            " 0.12295881 0.1223079  0.12227912 0.1221286  0.12166292 0.12107762\n",
            " 0.12079678 0.12078454 0.11986964 0.119605   0.11948723 0.11928915\n",
            " 0.11915747 0.11888622 0.11657818 0.11642405 0.11626754 0.11614512\n",
            " 0.11540957 0.1150275  0.11449336 0.11423437 0.11412128 0.11373821\n",
            " 0.11342193 0.11336237 0.11275176 0.1127137  0.11267481 0.11243755\n",
            " 0.11209361 0.11181295 0.1110651  0.11099324]\n",
            "[b'Person' b'Footwear' b'Footwear' b'Building' b'Person' b'Footwear'\n",
            " b'Window' b'Building' b'Person' b'Window' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Person' b'Footwear' b'Window' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Window' b'Window' b'Window' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Window' b'Person' b'Window' b'Window' b'Person' b'Window'\n",
            " b'Window' b'Window' b'Window' b'Window' b'Person' b'Building' b'Window'\n",
            " b'Window' b'Building' b'Person' b'Window' b'Person' b'Window' b'Window'\n",
            " b'Person' b'Window' b'Window' b'Building' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Window' b'Person' b'Window' b'Building' b'Window' b'Window'\n",
            " b'Window' b'Window' b'Window' b'Person' b'Window' b'Window' b'Window'\n",
            " b'Building' b'Window' b'Window' b'Window' b'Window' b'Building' b'Window'\n",
            " b'Building' b'Window' b'Building' b'Window' b'Window' b'Window'\n",
            " b'Bicycle' b'Window' b'Man' b'Window' b'Window' b'Window' b'Window'\n",
            " b'Window' b'Building' b'Building' b'Window' b'Building' b'Building'\n",
            " b'Building' b'Traffic light' b'Person' b'Window' b'Window']\n",
            "[[0.5130533  0.9170097  0.82187796 0.99240506]\n",
            " [0.8009514  0.954444   0.8311563  0.98134536]\n",
            " [0.79767334 0.94279504 0.8265182  0.9654046 ]\n",
            " [0.         0.         0.6767386  0.38946748]\n",
            " [0.49213943 0.41627944 0.68894947 0.46769166]\n",
            " [0.77776736 0.9472069  0.8027224  0.9622974 ]\n",
            " [0.01590109 0.34169227 0.14146212 0.36418098]\n",
            " [0.2632659  0.5653071  0.5527215  0.6749142 ]\n",
            " [0.49669468 0.37614486 0.66641665 0.42098722]\n",
            " [0.00217366 0.13283631 0.2132625  0.17361954]\n",
            " [0.         0.28114092 0.08157817 0.31303722]\n",
            " [0.05008128 0.75371903 0.12806374 0.8034256 ]\n",
            " [0.07553484 0.3932149  0.19646178 0.41355237]\n",
            " [0.05198066 0.8763429  0.2547093  0.9054911 ]\n",
            " [0.51977503 0.51613617 0.5979091  0.536872  ]\n",
            " [0.7524616  0.95581317 0.8063087  0.98124886]\n",
            " [0.         0.9702795  0.1630167  0.99979836]\n",
            " [0.00779123 0.10752927 0.23349738 0.18299852]\n",
            " [0.15529488 0.45481062 0.22104196 0.48166895]\n",
            " [0.07306564 0.3630629  0.17593941 0.3791245 ]\n",
            " [0.17808361 0.7477056  0.32032126 0.7763846 ]\n",
            " [0.13663228 0.27865112 0.27331662 0.30265242]\n",
            " [0.01376338 0.8118132  0.13418725 0.83949155]\n",
            " [0.17646399 0.3309348  0.33223715 0.35627922]\n",
            " [0.         0.14719884 0.2299796  0.19046213]\n",
            " [0.16281506 0.7448074  0.24337485 0.7742998 ]\n",
            " [0.1567135  0.2881579  0.2982093  0.31090543]\n",
            " [0.17442372 0.8143245  0.3546463  0.8381574 ]\n",
            " [0.00877662 0.30236045 0.10969231 0.32775602]\n",
            " [0.5298415  0.54492664 0.5879256  0.5648569 ]\n",
            " [0.09912397 0.75520486 0.15417914 0.78238994]\n",
            " [0.17180353 0.7086221  0.22657901 0.7287251 ]\n",
            " [0.5534452  0.603486   0.6423392  0.635981  ]\n",
            " [0.12867498 0.25131193 0.25569817 0.27327803]\n",
            " [0.14559221 0.32814223 0.26737323 0.35271472]\n",
            " [0.         0.32820293 0.08427357 0.35151955]\n",
            " [0.08580994 0.8820508  0.24959937 0.90945023]\n",
            " [0.00247406 0.         0.13664576 0.02405841]\n",
            " [0.5327079  0.60620236 0.58636856 0.6356164 ]\n",
            " [0.05298069 0.40561593 0.5896878  0.5666613 ]\n",
            " [0.19614987 0.706708   0.3166007  0.7270978 ]\n",
            " [0.12076892 0.40970913 0.21897335 0.4245532 ]\n",
            " [0.23859248 0.5913993  0.54063284 0.70409834]\n",
            " [0.4874188  0.21958667 0.69211555 0.2650162 ]\n",
            " [0.24153036 0.3917179  0.36476374 0.4119618 ]\n",
            " [0.5309534  0.7613163  0.58658195 0.7798215 ]\n",
            " [0.22045545 0.34866148 0.3391135  0.3669293 ]\n",
            " [0.16158052 0.48878297 0.22028796 0.5065986 ]\n",
            " [0.5062146  0.34393823 0.6283045  0.3680308 ]\n",
            " [0.04619356 0.88804615 0.24207526 0.92817307]\n",
            " [0.02630582 0.8467836  0.32541096 0.9250805 ]\n",
            " [0.00906625 0.7627823  0.6157321  0.99213594]\n",
            " [0.15413737 0.81961006 0.2695243  0.8421219 ]\n",
            " [0.2116244  0.42142907 0.27749002 0.45254222]\n",
            " [0.07052031 0.8154641  0.1661946  0.83793896]\n",
            " [0.02023774 0.38998613 0.1772731  0.4171367 ]\n",
            " [0.01961068 0.8675861  0.21998855 0.8978552 ]\n",
            " [0.53652096 0.7197321  0.5845356  0.73559564]\n",
            " [0.23398067 0.7536632  0.33830902 0.77558374]\n",
            " [0.         0.23563816 0.62044847 0.43200397]\n",
            " [0.2953548  0.45409134 0.3836685  0.47710183]\n",
            " [0.20362665 0.98390526 0.27636006 0.99953467]\n",
            " [0.20964542 0.41293752 0.2926384  0.4307456 ]\n",
            " [0.00287084 0.13008985 0.24428582 0.20907292]\n",
            " [0.08896473 0.24364473 0.21353921 0.26711774]\n",
            " [0.49858198 0.81168014 0.6020504  0.83322495]\n",
            " [0.09443285 0.2736549  0.20611136 0.29909155]\n",
            " [0.223836   0.50828743 0.27824247 0.5236583 ]\n",
            " [0.         0.2424253  0.03978967 0.26659963]\n",
            " [0.3629043  0.39186788 0.5368028  0.5963196 ]\n",
            " [0.00181294 0.21790113 0.20404038 0.24792345]\n",
            " [0.27080235 0.44689596 0.3606988  0.46755737]\n",
            " [0.24846283 0.70845747 0.337503   0.7259284 ]\n",
            " [0.08858725 0.9737036  0.1702416  0.9992733 ]\n",
            " [0.         0.14006996 0.64167666 0.40311962]\n",
            " [0.3251164  0.9028329  0.38408697 0.9282549 ]\n",
            " [0.318442   0.49946952 0.5405666  0.71175814]\n",
            " [0.00296184 0.81799203 0.07083921 0.841307  ]\n",
            " [0.         0.00347739 0.7310368  0.25557724]\n",
            " [0.11480786 0.44406116 0.18253915 0.4708982 ]\n",
            " [0.00266159 0.1549704  0.0740018  0.19228508]\n",
            " [0.11958864 0.14663213 0.23266044 0.18479723]\n",
            " [0.60900736 0.37198168 0.7105496  0.4208148 ]\n",
            " [0.11853824 0.14235325 0.22357798 0.17359956]\n",
            " [0.5130533  0.9170097  0.82187796 0.99240506]\n",
            " [0.00314304 0.89404655 0.22205329 0.9531336 ]\n",
            " [0.27483636 0.40561622 0.39095205 0.42244226]\n",
            " [0.38291052 0.895769   0.53349066 0.9321685 ]\n",
            " [0.00751371 0.3870072  0.07391989 0.42124036]\n",
            " [0.15789495 0.25278607 0.29835898 0.2734209 ]\n",
            " [0.         0.22460489 0.5798314  0.7052038 ]\n",
            " [0.0563474  0.3783724  0.5768994  0.6568786 ]\n",
            " [0.11866554 0.71959513 0.15072066 0.7353032 ]\n",
            " [0.22423865 0.43182802 0.5765763  0.56836903]\n",
            " [0.3469471  0.59292114 0.4598911  0.6253078 ]\n",
            " [0.         0.49563032 0.6007179  0.94298583]\n",
            " [0.4152669  0.50466764 0.48089895 0.5263741 ]\n",
            " [0.50134426 0.35418224 0.7065969  0.44499612]\n",
            " [0.3392518  0.7611535  0.38184997 0.78121775]\n",
            " [0.28022042 0.93485564 0.3215284  0.9517413 ]]\n"
          ]
        }
      ]
    }
  ]
}